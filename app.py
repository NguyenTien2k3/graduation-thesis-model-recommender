import pickle
import pandas as pd
from flask import Flask, request, jsonify
import os
import logging
import requests
import time

# ==========================================================================
# 1. Cáº¥u hÃ¬nh & Háº±ng sá»‘
# ==========================================================================
# Äáº·t cáº¥u hÃ¬nh log. Giá»¯ nguyÃªn má»©c INFO nhÆ°ng tá»‘i Æ°u hÃ³a cÃ¡c log bÃªn trong.
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)

app = Flask(__name__)

# CÃ¡c URL táº£i model vÃ  CSV
MODEL_HF_URL = "https://huggingface.co/Stas2k3/svd_model_nf32_lr0.001_reg0.05_reg0.05_ep40_p1.0_balanced/resolve/main/svd_model_nf32_lr0.001_reg0.05_ep40_p1.0_balanced.pkl"
CSV_HF_URL = "https://huggingface.co/datasets/Stas2k3/Cell_Phones_and_Accessories_Train/resolve/main/Cell_Phones_and_Accessories.train.csv"

# ÄÆ°á»ng dáº«n cache táº¡m
CACHE_DIR = "/tmp"
MODEL_PATH = os.path.join(CACHE_DIR, "model.pkl")
CSV_PATH = os.path.join(CACHE_DIR, "data.csv")

# ==========================================================================
# 2. HÃ m táº£i file tá»‘i Æ°u RAM (stream) vÃ  tá»‘i Æ°u LOG (FIX)
# ==========================================================================


def download_file_stream(url, save_path, name, max_retries=5):
    """Táº£i file theo luá»“ng (stream) Ä‘á»ƒ trÃ¡nh tá»‘n RAM vÃ  Ä‘Ã£ FIX lá»—i log spam."""
    if os.path.exists(save_path):
        # Giáº£m log khi file Ä‘Ã£ tá»“n táº¡i.
        logging.info(f"[{name}] File Ä‘Ã£ tá»“n táº¡i trong cache: {save_path}")
        return True

    for attempt in range(max_retries):
        try:
            logging.info(f"[{name}] Táº£i tá»« {url} (attempt {attempt + 1})...")
            with requests.get(url, stream=True, timeout=60) as r:
                r.raise_for_status()
                total_size = int(r.headers.get("content-length", 0))
                downloaded = 0
                
                # Biáº¿n má»›i Ä‘á»ƒ kiá»ƒm soÃ¡t log (Chá»‰ log khi vÆ°á»£t qua ngÆ°á»¡ng 20, 40, 60, 80)
                last_logged_step = 0 
                
                with open(save_path, "wb") as f:
                    for chunk in r.iter_content(chunk_size=8192):
                        if chunk:
                            f.write(chunk)
                            downloaded += len(chunk)
                            
                            if total_size:
                                percent = downloaded / total_size * 100
                                # TÃ­nh toÃ¡n ngÆ°á»¡ng hiá»‡n táº¡i (0, 20, 40, 60, 80)
                                current_step = int(percent // 20) * 20 

                                # Chá»‰ log khi vÆ°á»£t qua ngÆ°á»¡ng má»›i
                                if current_step > last_logged_step and current_step < 100:
                                    logging.info(f"[{name}] {current_step}% downloaded")
                                    last_logged_step = current_step
                                    
            # Log hoÃ n táº¥t chá»‰ Ä‘Æ°á»£c gá»i 1 láº§n khi thoÃ¡t khá»i vÃ²ng láº·p
            logging.info(f"[{name}] âœ… HoÃ n táº¥t táº£i: {save_path} (100%)")
            return True
        except Exception as e:
            logging.warning(f"[{name}] Lá»—i khi táº£i: {e}")
            if attempt < max_retries - 1:
                wait = 2 ** (attempt + 1)
                logging.info(f"[{name}] Äá»£i {wait}s trÆ°á»›c khi retry...")
                time.sleep(wait)
    logging.error(f"[{name}] âŒ Táº£i tháº¥t báº¡i sau {max_retries} láº§n.")
    return False


# ==========================================================================
# 3. Load dá»¯ liá»‡u
# ==========================================================================


def load_items():
    """Táº£i CSV báº±ng stream vÃ  Ä‘á»c tá»« file."""
    if not download_file_stream(CSV_HF_URL, CSV_PATH, "CSV Data"):
        return []
    try:
        logging.info("Äá»c CSV tá»« Ä‘Ä©a...")
        items_df = pd.read_csv(CSV_PATH)
        items_df["parent_asin"] = (
            items_df["parent_asin"].astype(str).str.split(",").str[0]
        )
        unique_items = items_df["parent_asin"].dropna().unique().tolist()
        logging.info(f"âœ… CSV Ä‘Ã£ load: {len(unique_items)} items duy nháº¥t.")
        return unique_items
    except Exception as e:
        logging.error(f"Lá»—i Ä‘á»c CSV: {e}")
        return []


def load_model():
    """Táº£i model pickle báº±ng stream."""
    if not download_file_stream(MODEL_HF_URL, MODEL_PATH, "Model"):
        return None
    try:
        with open(MODEL_PATH, "rb") as f:
            model = pickle.load(f)
        logging.info("âœ… Model Ä‘Ã£ load thÃ nh cÃ´ng.")
        return model
    except Exception as e:
        logging.error(f"Lá»—i load model: {e}")
        return None


# ==========================================================================
# 4. Khá»Ÿi Ä‘á»™ng dá»¯ liá»‡u toÃ n cá»¥c
# ==========================================================================

logging.info("ğŸš€ Khá»Ÿi Ä‘á»™ng server â€” báº¯t Ä‘áº§u load dá»¯ liá»‡u...")
item_ids = load_items()
topk_model = load_model()

# ==========================================================================
# 5. HÃ m gá»£i Ã½
# ==========================================================================


def get_top_k_recommendations(user_id, item_ids, model, k=10, blocked_items=None):
    if model is None:
        return [{"error": "Model not loaded"}]
    if not item_ids:
        return [{"error": "No items available"}]

    blocked_set = set(blocked_items or [])
    valid_items = [iid for iid in item_ids if iid not in blocked_set]
    if not valid_items:
        return [{"error": "No valid items"}]

    predictions = []
    # LÆ°u Ã½: KhÃ´ng thÃªm log vÃ o vÃ²ng láº·p nÃ y vÃ¬ nÃ³ cháº¡y ráº¥t nhiá»u láº§n 
    # trong má»—i yÃªu cáº§u API, dá»… gÃ¢y ra log spam trá»Ÿ láº¡i.
    for iid in valid_items:
        try:
            # Model.predict thÆ°á»ng lÃ  hÃ m tÃ­nh toÃ¡n phá»©c táº¡p
            pred = model.predict(uid=str(user_id), iid=str(iid)).est
            predictions.append((iid, pred))
        except Exception:
            continue

    if not predictions:
        return [{"error": "No predictions generated"}]

    predictions.sort(key=lambda x: x[1], reverse=True)
    return [
        {"item_id": iid, "predicted_rating": round(r, 2)} for iid, r in predictions[:k]
    ]


# ==========================================================================
# 6. API Endpoint
# ==========================================================================


@app.route("/recommend", methods=["POST"])
def recommend():
    data = request.get_json(force=True)
    user_id = data.get("user_id")
    k = int(data.get("top_k", 10))
    blocked_items = data.get("blocked_items", ["B00K30H3O8"])
    
    # CÃ³ thá»ƒ thÃªm log má»©c DEBUG á»Ÿ Ä‘Ã¢y náº¿u cáº§n, nhÆ°ng trÃ¡nh INFO/WARNING/ERROR
    # Ä‘á»ƒ khÃ´ng gÃ¢y spam trong quÃ¡ trÃ¬nh hoáº¡t Ä‘á»™ng bÃ¬nh thÆ°á»ng.
    
    if not user_id:
        return jsonify({"error": "user_id is required"}), 400
    recommendations = get_top_k_recommendations(
        user_id, item_ids, topk_model, k, blocked_items
    )
    return jsonify(recommendations), 200


@app.route("/health", methods=["GET"])
def health():
    return (
        jsonify(
            {
                "status": "healthy",
                "model_loaded": topk_model is not None,
                "items_count": len(item_ids),
            }
        ),
        200,
    )


if __name__ == "__main__":
    port = int(os.environ.get("PORT", 8000))
    app.run(host="0.0.0.0", port=port)
