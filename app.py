import pickle
import pandas as pd
from flask import Flask, request, jsonify
import os
import logging
import requests
import time
import threading # <-- Import má»›i Ä‘á»ƒ cháº¡y ná»n

# ==========================================================================
# 1. Cáº¥u hÃ¬nh & Háº±ng sá»‘
# ==========================================================================
# Thiáº¿t láº­p cáº¥u hÃ¬nh log cÆ¡ báº£n
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)

app = Flask(__name__)

# CÃ¡c URL táº£i model vÃ  CSV
MODEL_HF_URL = "https://huggingface.co/Stas2k3/svd_model_nf32_lr0.001_reg0.05_ep40_p1.0_balanced/resolve/main/svd_model_nf32_lr0.001_reg0.05_ep40_p1.0_balanced.pkl"
CSV_HF_URL = "https://huggingface.co/datasets/Stas2k3/Cell_Phones_and_Accessories_Train/resolve/main/Cell_Phones_and_Accessories.train.csv"

# ÄÆ°á»ng dáº«n cache táº¡m
CACHE_DIR = "/tmp"
MODEL_PATH = os.path.join(CACHE_DIR, "model.pkl")
CSV_PATH = os.path.join(CACHE_DIR, "data.csv")
# ÄÆ°á»ng dáº«n cache má»›i cho danh sÃ¡ch Item ID Ä‘Ã£ xá»­ lÃ½ (Tá»C Äá»˜ CAO)
ITEM_IDS_PATH = os.path.join(CACHE_DIR, "item_ids.pkl")

# Khá»Ÿi táº¡o dá»¯ liá»‡u toÃ n cá»¥c (sáº½ Ä‘Æ°á»£c cáº­p nháº­t sau)
item_ids = []
topk_model = None

# ==========================================================================
# 2. HÃ m táº£i file tá»‘i Æ°u RAM (stream)
# ==========================================================================

def download_file_stream(url, save_path, name, max_retries=5):
    """Táº£i file theo luá»“ng (stream) Ä‘á»ƒ trÃ¡nh tá»‘n RAM vÃ  giáº£m táº§n suáº¥t ghi log."""
    if os.path.exists(save_path):
        logging.info(f"[{name}] File Ä‘Ã£ tá»“n táº¡i trong cache: {save_path}")
        return True

    for attempt in range(max_retries):
        try:
            logging.info(f"[{name}] Táº£i tá»« {url} (attempt {attempt + 1})...")
            last_reported_percent = -1
            with requests.get(url, stream=True, timeout=60) as r:
                r.raise_for_status()
                total_size = int(r.headers.get("content-length", 0))
                downloaded = 0
                with open(save_path, "wb") as f:
                    for chunk in r.iter_content(chunk_size=8192):
                        if chunk:
                            f.write(chunk)
                            downloaded += len(chunk)
                            if total_size:
                                percent = downloaded / total_size * 100
                                # Chá»‰ ghi log khi tiáº¿n Ä‘á»™ vÆ°á»£t qua ngÆ°á»¡ng 20% má»›i
                                current_major_percent = int(percent // 20) * 20
                                if current_major_percent > last_reported_percent and current_major_percent < 100:
                                    logging.info(f"[{name}] {current_major_percent}% downloaded")
                                    last_reported_percent = current_major_percent

            logging.info(f"[{name}] âœ… HoÃ n táº¥t táº£i: {save_path}")
            return True
        except Exception as e:
            logging.warning(f"[{name}] Lá»—i khi táº£i: {e}")
            if attempt < max_retries - 1:
                wait = 2 ** (attempt + 1)
                logging.info(f"[{name}] Äá»£i {wait}s trÆ°á»›c khi retry...")
                time.sleep(wait)
    logging.error(f"[{name}] âŒ Táº£i tháº¥t báº¡i sau {max_retries} láº§n.")
    return False

# ==========================================================================
# 3. Load dá»¯ liá»‡u
# ==========================================================================

def _load_items_blocking():
    """Táº£i vÃ  load danh sÃ¡ch item ID (Sáº½ cháº¡y nhanh náº¿u cache tá»“n táº¡i)."""
    # 1. Thá»­ load tá»« cache nhanh ITEM_IDS_PATH
    if os.path.exists(ITEM_IDS_PATH):
        try:
            logging.info("Äang load Item IDs tá»« cache nhanh...")
            with open(ITEM_IDS_PATH, 'rb') as f:
                unique_items = pickle.load(f)
            logging.info(f"âœ… Item IDs Ä‘Ã£ load tá»« cache: {len(unique_items)} items duy nháº¥t.")
            return unique_items
        except Exception as e:
            logging.warning(f"Lá»—i Ä‘á»c cache Item IDs: {e}. Sáº½ load láº¡i tá»« CSV.")

    # 2. Náº¿u cache nhanh khÃ´ng tá»“n táº¡i hoáº·c lá»—i, fallback vá» CSV (quÃ¡ trÃ¬nh cháº­m)
    if not download_file_stream(CSV_HF_URL, CSV_PATH, "CSV Data"):
        return []
    
    try:
        logging.info("Äá»c CSV Tá»ª ÄÄ¨A (quÃ¡ trÃ¬nh cháº­m)...")
        items_df = pd.read_csv(CSV_PATH)
        # Xá»­ lÃ½ cá»™t parent_asin Ä‘á»ƒ chá»‰ láº¥y ASIN Ä‘áº§u tiÃªn náº¿u lÃ  danh sÃ¡ch
        items_df["parent_asin"] = (
            items_df["parent_asin"].astype(str).str.split(",").str[0]
        )
        unique_items = items_df["parent_asin"].dropna().unique().tolist()
        logging.info(f"âœ… CSV Ä‘Ã£ load vÃ  xá»­ lÃ½: {len(unique_items)} items duy nháº¥t.")

        # 3. LÆ°u káº¿t quáº£ xá»­ lÃ½ vÃ o cache nhanh ITEM_IDS_PATH
        try:
            with open(ITEM_IDS_PATH, 'wb') as f:
                pickle.dump(unique_items, f)
            logging.info("âœ… ÄÃ£ táº¡o cache nhanh Item IDs.")
        except Exception as e:
            logging.warning(f"Lá»—i khi lÆ°u cache Item IDs: {e}")

        return unique_items
    except Exception as e:
        logging.error(f"Lá»—i Ä‘á»c CSV: {e}")
        return []

def _load_model_blocking():
    """Táº£i model pickle báº±ng stream (blocking operation)."""
    if not download_file_stream(MODEL_HF_URL, MODEL_PATH, "Model"):
        return None
    try:
        logging.info("Äang load Model tá»« Ä‘Ä©a (quÃ¡ trÃ¬nh cháº­m)...")
        with open(MODEL_PATH, "rb") as f:
            model = pickle.load(f)
        logging.info("âœ… Model Ä‘Ã£ load thÃ nh cÃ´ng.")
        return model
    except Exception as e:
        logging.error(f"Lá»—i load model: {e}")
        return None

# ==========================================================================
# 4. Khá»Ÿi Ä‘á»™ng dá»¯ liá»‡u báº¥t Ä‘á»“ng bá»™ (ASYNC)
# ==========================================================================

def load_data_and_model_async():
    """HÃ m má»¥c tiÃªu cho luá»“ng ná»n, chá»‹u trÃ¡ch nhiá»‡m load dá»¯ liá»‡u vÃ  model."""
    global item_ids, topk_model
    logging.info("ðŸš€ Luá»“ng ná»n: Báº¯t Ä‘áº§u táº£i Item IDs (nhanh) vÃ  Model (cháº­m)...")
    
    # 1. Táº£i Item IDs (Váº«n giá»¯ synchronous vÃ¬ nÃ³ Ä‘Ã£ nhanh)
    item_ids = _load_items_blocking()
    
    # 2. Táº£i Model (Pháº§n cháº­m, nhÆ°ng Ä‘ang cháº¡y á»Ÿ luá»“ng ná»n)
    topk_model = _load_model_blocking()
    
    logging.info("âœ… Luá»“ng ná»n: HoÃ n táº¥t táº¥t cáº£ quÃ¡ trÃ¬nh load dá»¯ liá»‡u.")


# ==========================================================================
# 5. HÃ m gá»£i Ã½
# ==========================================================================

def get_top_k_recommendations(user_id, current_item_ids, model, k=10, blocked_items=None):
    # Kiá»ƒm tra model trÆ°á»›c khi cháº¡y
    if model is None:
        logging.error("Model chÆ°a Ä‘Æ°á»£c load. KhÃ´ng thá»ƒ gá»£i Ã½.")
        return [{"error": "Model not loaded"}]
    
    if not current_item_ids:
        logging.error("KhÃ´ng cÃ³ danh sÃ¡ch items. KhÃ´ng thá»ƒ gá»£i Ã½.")
        return [{"error": "No items available"}]

    blocked_set = set(blocked_items or [])
    valid_items = [iid for iid in current_item_ids if iid not in blocked_set]
    if not valid_items:
        logging.warning("KhÃ´ng cÃ²n items há»£p lá»‡ sau khi loáº¡i bá» blocked_items.")
        return [{"error": "No valid items"}]

    predictions = []
    # LÆ°u Ã½: Viá»‡c láº·p qua Táº¤T Cáº¢ items (94k+) vÃ  gá»i predict lÃ  ráº¥t tá»‘n thá»i gian.
    # ÄÃ¢y váº«n lÃ  Ä‘iá»ƒm cáº§n tá»‘i Æ°u hÃ³a hiá»‡u suáº¥t sau khi giáº£i quyáº¿t váº¥n Ä‘á» khá»Ÿi Ä‘á»™ng.
    start_time = time.time()
    for iid in valid_items:
        try:
            # Model.predict() Æ°á»›c tÃ­nh rating cho cáº·p (user, item)
            # Sá»­ dá»¥ng global topk_model Ä‘Æ°á»£c cáº­p nháº­t tá»« luá»“ng ná»n
            pred = model.predict(uid=str(user_id), iid=str(iid)).est
            predictions.append((iid, pred))
        except Exception:
            # Bá» qua náº¿u item hoáº·c user ID khÃ´ng cÃ³ trong dá»¯ liá»‡u huáº¥n luyá»‡n
            continue

    end_time = time.time()
    logging.info(f"ÄÃ£ táº¡o {len(predictions)} dá»± Ä‘oÃ¡n trong {end_time - start_time:.2f}s.")

    if not predictions:
        return [{"error": "No predictions generated"}]

    predictions.sort(key=lambda x: x[1], reverse=True)
    return [
        {"item_id": iid, "predicted_rating": round(r, 2)}
        for iid, r in predictions[:k]
    ]

# ==========================================================================
# 6. API Endpoint
# ==========================================================================

@app.route("/recommend", methods=["POST"])
def recommend():
    # Kiá»ƒm tra tráº¡ng thÃ¡i model trÆ°á»›c khi xá»­ lÃ½ request
    if topk_model is None:
        logging.warning("YÃªu cáº§u gá»£i Ã½ tháº¥t báº¡i: Model Ä‘ang Ä‘Æ°á»£c táº£i.")
        # Tráº£ vá» lá»—i 503 (Service Unavailable) náº¿u model chÆ°a load xong
        return jsonify({"error": "Model is still loading. Please try again in a few seconds."}), 503
    
    try:
        data = request.get_json(force=True)
    except Exception as e:
        return jsonify({"error": f"Invalid JSON payload: {e}"}), 400

    user_id = data.get("user_id")
    k = int(data.get("top_k", 10))
    blocked_items = data.get("blocked_items", [])

    if not user_id:
        return jsonify({"error": "user_id is required"}), 400

    logging.info(f"YÃªu cáº§u gá»£i Ã½ cho user_id: {user_id}, top_k: {k}")

    # Truyá»n biáº¿n item_ids vÃ  topk_model Ä‘Ã£ Ä‘Æ°á»£c cáº­p nháº­t bá»Ÿi luá»“ng ná»n
    recommendations = get_top_k_recommendations(user_id, item_ids, topk_model, k, blocked_items)

    # ThÃªm kiá»ƒm tra lá»—i cuá»‘i cÃ¹ng
    if recommendations and "error" in recommendations[0]:
        return jsonify({"error": recommendations[0]["error"]}), 500

    return jsonify(recommendations), 200

@app.route("/health", methods=["GET"])
def health():
    # Health check pháº£n Ã¡nh tráº¡ng thÃ¡i cá»§a model
    return jsonify({
        "status": "healthy",
        # Tráº£ vá» false trong 8-9 giÃ¢y Ä‘áº§u
        "model_loaded": topk_model is not None, 
        "items_count": len(item_ids)
    }), 200

if __name__ == "__main__":
    # Báº¯t Ä‘áº§u luá»“ng ná»n Ä‘á»ƒ táº£i dá»¯ liá»‡u vÃ  model
    threading.Thread(target=load_data_and_model_async, daemon=True).start()
    
    # Server Flask báº¯t Ä‘áº§u cháº¡y ngay láº­p tá»©c
    logging.info("âœ… Server Flask báº¯t Ä‘áº§u láº¯ng nghe cá»•ng (Startup Time < 1s)...")
    port = int(os.environ.get("PORT", 8000))
    app.run(host="0.0.0.0", port=port)
