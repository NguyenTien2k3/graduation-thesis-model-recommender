import pickle
import pandas as pd
from flask import Flask, request, jsonify
import os
import logging
import requests
import time
import sys # Th√™m sys ƒë·ªÉ ki·ªÉm tra k√≠ch th∆∞·ªõc ƒë·ªëi t∆∞·ª£ng

# ==========================================================================
# 1. C·∫•u h√¨nh & H·∫±ng s·ªë
# ==========================================================================
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)

app = Flask(__name__)

# C√°c URL t·∫£i
MODEL_HF_URL = "https://huggingface.co/Stas2k3/svd_model_nf32_lr0.001_reg0.05_ep40_p1.0_balanced/resolve/main/svd_model_nf32_lr0.001_reg0.05_ep40_p1.0_balanced.pkl"
# üö® URL M·ªöI: Thay th·∫ø CSV b·∫±ng file pickle ch·ª©a list item IDs ƒë√£ ƒë∆∞·ª£c ti·ªÅn x·ª≠ l√Ω
ITEM_IDS_HF_URL = "https://huggingface.co/datasets/Stas2k3/Cell_Phones_and_Accessories_Train/resolve/main/item_ids.pkl" 
# B·∫°n c·∫ßn thay URL n√†y b·∫±ng URL c·ªßa file item_ids.pkl m√† b·∫°n ƒë√£ upload

# ƒê∆∞·ªùng d·∫´n cache t·∫°m
CACHE_DIR = "/tmp"
MODEL_PATH = os.path.join(CACHE_DIR, "model.pkl")
ITEM_IDS_PATH = os.path.join(CACHE_DIR, "item_ids.pkl")

# ==========================================================================
# 2. H√†m t·∫£i file t·ªëi ∆∞u RAM (stream)
# ==========================================================================


def download_file_stream(url, save_path, name, max_retries=5):
    """T·∫£i file theo lu·ªìng (stream) ƒë·ªÉ tr√°nh t·ªën RAM."""
    if os.path.exists(save_path):
        logging.info(f"[{name}] File ƒë√£ t·ªìn t·∫°i trong cache: {save_path}")
        return True

    for attempt in range(max_retries):
        try:
            logging.info(f"[{name}] T·∫£i t·ª´ {url} (attempt {attempt + 1})...")
            with requests.get(url, stream=True, timeout=60) as r:
                r.raise_for_status()
                # Th√™m log ki·ªÉm tra k√≠ch th∆∞·ªõc file ƒë·ªÉ theo d√µi
                total_size_bytes = int(r.headers.get("content-length", 0))
                total_size_mb = total_size_bytes / (1024 * 1024)
                logging.info(f"[{name}] K√≠ch th∆∞·ªõc file: {total_size_mb:.2f} MB")
                
                downloaded = 0
                with open(save_path, "wb") as f:
                    for chunk in r.iter_content(chunk_size=8192):
                        if chunk:
                            f.write(chunk)
                            downloaded += len(chunk)
                            # B·ªè log % t·∫£i xu·ªëng ƒë·ªÉ gi·∫£m I/O v√† tƒÉng t·ªëc
                            
                logging.info(f"[{name}] ‚úÖ Ho√†n t·∫•t t·∫£i: {save_path}")
                return True
        except Exception as e:
            logging.warning(f"[{name}] L·ªói khi t·∫£i: {e}")
            if attempt < max_retries - 1:
                wait = 2 ** (attempt + 1)
                logging.info(f"[{name}] ƒê·ª£i {wait}s tr∆∞·ªõc khi retry...")
                time.sleep(wait)
    logging.error(f"[{name}] ‚ùå T·∫£i th·∫•t b·∫°i sau {max_retries} l·∫ßn.")
    return False


# ==========================================================================
# 3. Load d·ªØ li·ªáu (ƒê√£ t·ªëi ∆∞u)
# ==========================================================================


def load_items():
    """T·∫£i v√† ƒë·ªçc list Item ID t·ª´ file pickle si√™u nh·ªè g·ªçn."""
    if not download_file_stream(ITEM_IDS_HF_URL, ITEM_IDS_PATH, "Item IDs"):
        return []
    try:
        logging.info("ƒê·ªçc Item IDs t·ª´ ƒëƒ©a...")
        with open(ITEM_IDS_PATH, "rb") as f:
            item_ids = pickle.load(f)
        
        # Th√™m log ki·ªÉm tra RAM s·ª≠ d·ª•ng
        size_mb = sys.getsizeof(item_ids) / (1024 * 1024)
        logging.info(f"‚úÖ Item IDs ƒë√£ load: {len(item_ids)} items duy nh·∫•t. RAM: {size_mb:.2f} MB")
        return item_ids
    except Exception as e:
        logging.error(f"L·ªói ƒë·ªçc Item IDs: {e}")
        return []


def load_model():
    """T·∫£i model pickle b·∫±ng stream."""
    if not download_file_stream(MODEL_HF_URL, MODEL_PATH, "Model"):
        return None
    try:
        with open(MODEL_PATH, "rb") as f:
            model = pickle.load(f)
        
        # Th√™m log ki·ªÉm tra RAM s·ª≠ d·ª•ng
        size_mb = sys.getsizeof(model) / (1024 * 1024)
        logging.info(f"‚úÖ Model ƒë√£ load th√†nh c√¥ng. RAM: {size_mb:.2f} MB")
        return model
    except Exception as e:
        logging.error(f"L·ªói load model: {e}")
        return None


# ==========================================================================
# 4. Kh·ªüi ƒë·ªông d·ªØ li·ªáu to√†n c·ª•c
# ==========================================================================

logging.info("üöÄ Kh·ªüi ƒë·ªông server ‚Äî b·∫Øt ƒë·∫ßu load d·ªØ li·ªáu...")
item_ids = load_items()
topk_model = load_model()

# Ki·ªÉm tra sau khi load
if topk_model is None or not item_ids:
    logging.error("üö® Kh√¥ng th·ªÉ load Model ho·∫∑c Item IDs. D·ªãch v·ª• s·∫Ω b·ªã l·ªói.")

# ==========================================================================
# 5. H√†m g·ª£i √Ω
# ==========================================================================


def get_top_k_recommendations(user_id, item_ids, model, k=10, blocked_items=None):
    if model is None:
        return [{"error": "Model not loaded"}]
    if not item_ids:
        return [{"error": "No items available"}]

    blocked_set = set(blocked_items or [])
    # Ch·ªâ gi·ªØ l·∫°i c√°c ASIN c√≥ √≠t nh·∫•t m·ªôt k√Ω t·ª± v√† kh√¥ng n·∫±m trong blocked_set
    valid_items = [iid for iid in item_ids if iid and iid not in blocked_set]
    
    if not valid_items:
        return [{"error": "No valid items"}]
    
    # Gi·ªõi h·∫°n s·ªë l∆∞·ª£ng d·ª± ƒëo√°n ƒë·ªÉ tr√°nh timeout/OOM n·∫øu list item_ids qu√° l·ªõn
    # N·∫øu list ID qu√° l·ªõn (v√≠ d·ª• > 50k), b·∫°n n√™n l·∫•y m·∫´u ng·∫´u nhi√™n (sampling)
    # ho·∫∑c d√πng c√°c h√†m t·ªëi ∆∞u h∆°n c·ªßa Surprise (get_top_n)
    
    predictions = []
    
    # S·ª≠ d·ª•ng m√¥ h√¨nh (Surprise SVD) ƒë·ªÉ d·ª± ƒëo√°n
    for iid in valid_items:
        try:
            # model.predict y√™u c·∫ßu uid v√† iid l√† chu·ªói (str)
            pred = model.predict(uid=str(user_id), iid=str(iid)).est
            predictions.append((iid, pred))
        except Exception:
            # B·ªè qua n·∫øu c√≥ l·ªói (v√≠ d·ª•: Item ID ho·∫∑c User ID kh√¥ng c√≥ trong m√¥ h√¨nh)
            continue

    if not predictions:
        # N·∫øu m√¥ h√¨nh kh√¥ng t·∫°o ra d·ª± ƒëo√°n n√†o cho user n√†y
        # C√≥ th·ªÉ d√πng m·ªôt chi·∫øn l∆∞·ª£c d·ª± ph√≤ng (fallback) ·ªü ƒë√¢y
        return [{"error": "No predictions generated or user unknown"}]

    predictions.sort(key=lambda x: x[1], reverse=True)
    
    return [
        {"item_id": iid, "predicted_rating": round(r, 2)} for iid, r in predictions[:k]
    ]


# ==========================================================================
# 6. API Endpoint
# ==========================================================================


@app.route("/recommend", methods=["POST"])
def recommend():
    try:
        data = request.get_json(force=True)
    except Exception as e:
        return jsonify({"error": f"Invalid JSON payload: {e}"}), 400

    user_id = data.get("user_id")
    k = int(data.get("top_k", 10))
    # S·ª≠ d·ª•ng gi√° tr·ªã m·∫∑c ƒë·ªãnh √≠t g√¢y tranh c√£i h∆°n, ho·∫∑c ƒë·ªÉ r·ªóng
    blocked_items = data.get("blocked_items", []) 
    
    if not user_id:
        return jsonify({"error": "user_id is required"}), 400
    
    if topk_model is None or not item_ids:
        return jsonify({"error": "Service not ready: Model or Items not loaded"}), 503

    recommendations = get_top_k_recommendations(
        user_id, item_ids, topk_model, k, blocked_items
    )
    return jsonify(recommendations), 200


@app.route("/health", methods=["GET"])
def health():
    return (
        jsonify(
            {
                "status": "healthy",
                "model_loaded": topk_model is not None,
                "items_count": len(item_ids) if item_ids else 0,
            }
        ),
        200,
    )


if __name__ == "__main__":
    port = int(os.environ.get("PORT", 8000))
    logging.info(f"Web server starting on port {port}")
    app.run(host="0.0.0.0", port=port)